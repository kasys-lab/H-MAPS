{"timestamp": 1770879757.0862725, "dt_str": "2026-02-12 16:02:37", "events": [{"question": "1. What studies explore methods for incorporating reflection tokens in Human-AI collaboration systems to enhance trust and transparency in model outputs?", "papers": [{"paper_id": 249114869, "title": "Designing Transparency for Effective Human-AI Collaboration", "url": null, "summary": "\nThe field of artificial intelligence (AI) is advancing quickly, and systems can increasingly perform a multitude of tasks that previously required human intelligence. Information systems can facilitate collaboration between humans and AI systems such that their individual capabilities complement each other. However, there is a lack of consolidated design guidelines for information systems facilitating the collaboration between humans and AI systems. This work examines how agent transparency affects trust and task outcomes in the context of human-AI collaboration. Drawing on the 3-Gap framework, we study agent transparency as a means to reduce the information asymmetry between humans and the AI. Following the Design Science Research paradigm, we formulate testable propositions, derive desig"}, {"paper_id": 232414194, "title": "Investigating the relationship between AI and trust in human-AI collaboration", "url": null, "summary": "\nWith the increasing development of information technology, the implementation of artificial intelligence (AI) has been widespread and has empowered virtual team collaboration by increasing collaboration efficiency and achieving superior collaboration results in recent years. Trust in the process of human-AI interaction has been identified as a challenge for team collaboration in this context. However, little research has investigated the relationship between human-AI interaction and trust. This study proposes a theoretical model of the relationship between human-AI interaction and team members’ trust during collaboration processes. We conclude that tea m members’ cognitive and emotional perceptions during the interaction process are associated with their trust towards AI. Moreover, the rel"}, {"paper_id": 259224547, "title": "Critical-Reflective Human-AI Collaboration: Exploring Computational Tools for Art Historical Image Retrieval", "url": null, "summary": "\nJust as other disciplines, the humanities explore how computational research approaches and tools can meaningfully contribute to scholarly knowledge production. Building on related work from the areas of CSCW and HCI, we approach the design of computational tools through the analytical lens of 'human-AI collaboration.' Such work investigates how human competencies and computational capabilities can be effectively and meaningfully combined. However, there is no generalizable concept of what constitutes 'meaningful' human-AI collaboration. In terms of genuinely human competencies, we consider criticality and reflection as guiding principles of scholarly knowledge production and as deeply embedded in the methodologies and practices of the humanities. Although (designing for) reflection is a r"}, {"paper_id": 268856808, "title": "Collaborative human-AI trust (CHAI-T): A process framework for active management of trust in human-AI collaboration", "url": null, "summary": "\nCollaborative human-AI (HAI) teaming combines the unique skills and capabilities of humans and machines in sustained teaming interactions leveraging the strengths of each. In tasks involving regular exposure to novelty and uncertainty, collaboration between adaptive, creative humans and powerful, precise artificial intelligence (AI) promises new solutions and efficiencies. User trust is essential to creating and maintaining these collaborative relationships. Established models of trust in traditional forms of AI typically recognize the contribution of three primary categories of trust antecedents: characteristics of the human user, characteristics of the technology, and environmental factors. The emergence of HAI teams, however, requires an understanding of human trust that accounts for th"}, {"paper_id": 248420019, "title": "Trust in Human-AI Interaction: Scoping Out Models, Measures, and Methods", "url": null, "summary": "\nTrust has emerged as a key factor in people's interactions with AI-infused systems. Yet, little is known about what models of trust have been used and for what systems: robots, virtual characters, smart vehicles, decision aids, or others. Moreover, there is yet no known standard approach to measuring trust in AI. This scoping review maps out the state of affairs on trust in human-AI interaction (HAII) from the perspectives of models, measures, and methods. Findings suggest that trust is an important and multi-faceted topic of study within HAII contexts. However, most work is under-theorized and under-reported, generally not using established trust models and missing details about methods, especially Wizard of Oz. We offer several targets for systematic review work as well as a research age"}]}, {"question": "2. Are there any research papers that focus on training Conditional Language Models (CLMs) or similar systems to generate reflection tokens for improving user understanding of AI-generated content?", "papers": [{"paper_id": 218516636, "title": "Token Manipulation Generative Adversarial Network for Text Generation", "url": null, "summary": "\nMaskGAN opens the query for the conditional language model by filling in the blanks between the given tokens. In this paper, we focus on addressing the limitations caused by having to specify blanks to be filled. We decompose conditional text generation problem into two tasks, make-a-blank and fill-in-the-blank, and extend the former to handle more complex manipulations on the given tokens. We cast these tasks as a hierarchical multi agent RL problem and introduce a conditional adversarial learning that allows the agents to reach a goal, producing realistic texts, in cooperative setting. We show that the proposed model not only addresses the limitations but also provides good results without compromising the performance in terms of quality and diversity."}, {"paper_id": 266176891, "title": "Conditional Natural Language Inference", "url": null, "summary": "\n,"}, {"paper_id": 252668614, "title": "Out-of-Distribution Detection and Selective Generation for Conditional Language Models", "url": null, "summary": "\nMachine learning algorithms typically assume independent and identically distributed samples in training and at test time. Much work has shown that high-performing ML classifiers can degrade significantly and provide overly-confident, wrong classification predictions, particularly for out-of-distribution (OOD) inputs. Conditional language models (CLMs) are predominantly trained to classify the next token in an output sequence, and may suffer even worse degradation on OOD inputs as the prediction is done auto-regressively over many steps. Furthermore, the space of potential low-quality outputs is larger as arbitrary text can be generated and it is important to know when to trust the generated output. We present a highly accurate and lightweight OOD detection method for CLMs, and demonstrate"}, {"paper_id": 247363011, "title": "Conditional Prompt Learning for Vision-Language Models", "url": null, "summary": "\nWith the rise of powerful pre-trained vision-language models like CLIP, it becomes essential to investigate ways to adapt these models to downstream datasets. A recently proposed method named Context Optimization (CoOp) introduces the concept of prompt learning—a recent trend in NLP—to the vision domain for adapting pre-trained vision-language models. Specifically, CoOp turns context words in a prompt into a set of learnable vectors and, with only a few labeled images for learning, can achieve huge improvements over intensively-tuned manual prompts. In our study we identify a critical problem of CoOp: the learned context is not generalizable to wider unseen classes within the same dataset, suggesting that CoOp overfits base classes observed during training. To address the problem, we propo"}, {"paper_id": 237259899, "title": "CIGLI: Conditional Image Generation from Language & Image", "url": null, "summary": "\nMulti-modal generation has been widely explored in recent years. Current research directions involve generating text based on an image or vice versa. In this paper, we propose a new task called CIGLI: Conditional Image Generation from Language and Image. Instead of generating an image based on text as in text-image generation, this task requires the generation of an image from a textual description and an image prompt. We designed a new dataset to ensure that the text description describes information from both images, and that solely analyzing the description is insufficient to generate an image. We then propose a novel language-image fusion model which improves the performance over two established baseline methods, as evaluated by quantitative (automatic) and qualitative (human) evaluati"}]}, {"question": "3. What work has been done on using visualization techniques for evaluating or representing the relevance and citation support of generated text in Retrieval-Augmented Generation models?", "papers": [{"paper_id": 246472929, "title": "A Survey on Retrieval-Augmented Text Generation", "url": null, "summary": "\nRecently, retrieval-augmented text generation attracted increasing attention of the computational linguistics community. Compared with conventional generation models, retrieval-augmented text generation has remarkable advantages and particularly has achieved state-of-the-art performance in many NLP tasks. This paper aims to conduct a survey about retrieval-augmented text generation. It firstly highlights the generic paradigm of retrieval-augmented generation, and then it reviews notable approaches according to different tasks including dialogue response generation, machine translation, and other generation tasks. Finally, it points out some important directions on top of recent methods to facilitate future research."}, {"paper_id": 273811828, "title": "RAGViz: Diagnose and Visualize Retrieval-Augmented Generation", "url": null, "summary": "\nRetrieval-augmented generation (RAG) combines knowledge from domain-specific sources into large language models to ground answer generation. Current RAG systems lack customizable visibility on the context documents and the model’s attentiveness towards such documents. We propose RAGViz, a RAG diagnosis tool that visualizes the attentiveness of the generated tokens in retrieved documents. With a built-in user interface, retrieval index, and Large Language Model (LLM) backbone, RAGViz provides two main functionalities: (1) token and document-level attention visualization, and (2) generation comparison upon context document addition and removal. As an open-source toolkit, RAGViz can be easily hosted with a custom embedding model and HuggingFace-supported LLM backbone. Using a hybrid ANN (Appr"}, {"paper_id": 269293655, "title": "Evaluating Retrieval Quality in Retrieval-Augmented Generation", "url": null, "summary": "\nEvaluating retrieval-augmented generation (RAG) presents challenges, particularly for retrieval models within these systems. Traditional end-to-end evaluation methods are computationally expensive. Furthermore, evaluation of the retrieval model's performance based on query-document relevance labels shows a small correlation with the RAG system's downstream performance. We propose a novel evaluation approach, eRAG, where each document in the retrieval list is individually utilized by the large language model within the RAG system. The output generated for each document is then evaluated based on the downstream task ground truth labels. In this manner, the downstream performance for each document serves as its relevance label. We employ various downstream task metrics to obtain document-leve"}, {"paper_id": 270870251, "title": "Searching for Best Practices in Retrieval-Augmented Generation", "url": null, "summary": "\nRetrieval-augmented generation (RAG) techniques have proven to be effective in integrating up-to-date information, mitigating hallucinations, and enhancing response quality, particularly in specialized domains. While many RAG approaches have been proposed to enhance large language models through query-dependent retrievals, these approaches still suffer from their complex implementation and prolonged response times. Typically, a RAG workflow involves multiple processing steps, each of which can be executed in various ways. Here, we investigate existing RAG approaches and their potential combinations to identify optimal RAG practices. Through extensive experiments, we suggest several strategies for deploying RAG that balance both performance and efficiency. Moreover, we demonstrate that mult"}, {"paper_id": 252568176, "title": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation", "url": null, "summary": "\nRetrieval-augmented generation models offer many benefits over standalone language models: besides a textual answer to a given query they provide provenance items retrieved from an updateable knowledge base. However, they are also more complex systems and need to handle long inputs. In this work, we introduce FiD-Light to strongly increase the efficiency of the state-of-the-art retrieval-augmented FiD model, while maintaining the same level of effectiveness. Our FiD-Light model constrains the information flow from the encoder (which encodes passages separately) to the decoder (using concatenated encoded representations). Furthermore, we adapt FiD-Light with re-ranking capabilities through textual source pointers, to improve the top-ranked provenance precision. Our experiments on a diverse "}]}]}
